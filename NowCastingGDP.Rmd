---
title: "NowCasting GDP"
author: "Minhaz Khan, Navin Chandradat, Bobak Ahmar, Vincent La"
date: "14/09/2019"
output: html_document
---
The problem that we will be tackling is the prediction of the quarters of the fiscal year. To do this, we will employ a technique called 
NowCasting, which is the prediction of the current, and near future by examining data that occur at different frequencies and with 
different lags. To begin, we'll first plot the monthly and quarterly GDPs against eachother. Next, we will fit a model based on the data 
provided and examine the correlation between different months and quarters.

```{r, fig.height=3, fig.width=5}
# load required packages
library(cansim)
library(tidyverse)
library(lubridate)
library(modelr)
library(broom)
library(astsa)
library(forecast)
library(xts) # better ts objects, including quarterly series

#### Problem 2 ####

# plot quarterly & monthly GDP 
#This code is from the Draft
get_cansim_vector( c( 
  "monthly GDP" = "v65201210",
  "quarterly GDP" = "v1000000673") ,
    start_time = "2015-01-01" ) %>% 
  normalize_cansim_values() %>% 
  ggplot( aes( x = Date, y = VALUE, col = label ) ) +
  geom_line() + geom_point() + ylab("Chained (2012) dollars") +
  ggtitle("Problem 2: Plot of quarterly & monthly GDP")


```
The graph shows that both the monthly and quarterly GDPs increase at almost exactly the same rate. This suggests that
perhaps the two are highly correlated.


In order to get a closer look at the existing pattern, we separated the monthly and quarterly GDP and then graphed them.
```{r}
get_cansim_vector( c( 
  "monthly GDP (basic prices)" = "v65201210",
  "quarterly GDP (expend-based)" = "v62305723") ,
    start_time = "2010-01-01" ) %>% 
  normalize_cansim_values() %>% 
  ggplot( aes( x = Date, y = VALUE, col = label ) ) +
  geom_line() + geom_point() + ylab("Chained (2012) dollars")
```

Retrieving the data frame:
```{r}
get_cansim_vector( c( 
  "monthly GDP (basic prices)" = "v65201210",
  "quarterly GDP (expend-based)" = "v62305723") ,
    start_time = "2009-01-01" ) %>% 
    normalize_cansim_values() -> ncastDF
```

Summary Statistics for monthly and quarterly data
```{r}
ncastDF %>% group_by(label) %>% summarise(time_mean = mean(VALUE), time_var = var(VALUE), time_med = median(VALUE))
```

Spreading the labels to their own columns for model testing
```{r}
ncastDF %>% spread(label,VALUE) -> ncastSP
ncastSP
```

Checking out the yearly pattern for some quarters and months
```{r}
glimpse(ncastDF)
ncastDF %>% filter(label == "quarterly GDP (expend-based)" & year(Date) ==2010) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()

ncastDF %>% filter(label == "monthly GDP (basic prices)" & year(Date) ==2010) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()
ncastDF %>% filter(label == "monthly GDP (basic prices)" & year(Date) ==2011) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()
ncastDF %>% filter(label == "monthly GDP (basic prices)" & year(Date) ==2012) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()
ncastDF %>% filter(label == "monthly GDP (basic prices)" & year(Date) ==2013) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()
```


```{r}
ggplot(ncast.1,aes(x=Date,y= VALUE,group = Date))+geom_boxplot()

```

Here, we can see that the variance between the values are more or less the same time progresses, while the mean steadily increases in an almost linear fashion.


Taking a sample year to work with:
```{r}
ncastSP %>% filter(year(Date) >= 2018 & year(Date) <= 2019) -> ncast1


ncast1 %>% mutate(monthly = case_when(
                                  `monthly GDP (basic prices)` == NA ~ 0, 
                                  is.na(`monthly GDP (basic prices)`) ~ 0,
                                  TRUE ~ `monthly GDP (basic prices)`)) %>%
  mutate(quarterly = case_when(
                                  `quarterly GDP (expend-based)` == NA ~ 0, 
                                  is.na(`quarterly GDP (expend-based)`) ~ 0,
                                  TRUE ~ `quarterly GDP (expend-based)`)) %>% 
  select(REF_DATE,releaseTime,Date,monthly,quarterly) -> ncastMQ



```
Replaced the NA with zeroes to work with models and other analysis.


Sample model exploring the relationship between the quarterly and monthly values
```{r}
cor(ncastMQ$quarterly,ncastMQ$monthly)
ncast.lm = lm(quarterly~monthly+Date,data = ncastMQ)
summary(ncast.lm)
```
The model is off due to majority of the zeroes in our data


```{r}
ncastMQ %>% spread(Date,monthly) 
```
Ideal data frame to test the prediction of each quarter within a 3 month cohort.

*Plan of Attack*
Since the data we have is clearly dependent, i.e. the GDP for previous months would be dependent on eachother, we could use time series 
methodologies to estimate the present and near future, in particular, we will attempt to fit an ARMA model for the data.

In order to do this, we must construct a model of our time series. The essence of how we want to construct our model is that we want to 
create a three month cohort for each quarter and attach them together. So what this means is that we want to create these quarterly bins 
for each month starting with one year and experimenting with that. For example, if we were to predict the GDP for the first quarter of 
2019, we would use the monthly GDP data from the previous 3 months. 

Furthermore, in order to make full use of these methodologies, we’ll also check that our model is stationary. We may obtain evidence of 
this by looking back even further, and see if there are any discrepancies between the joint distribution of monthly GDPs, by using ACF 
and PACF plots. Additionally, we may check if the mean and variance functions are constant, or if γ(s,t) is function of h = s-t. If at 
least one of these are not fulfilled we may have to change our model such that it will. There also may be the problem of seasonality in 
the mean, for example the GDP of a country that relies heavily on tourist will fluctuate up and down throughout the year. In this case, 
we could employ the moving average smoother to get rid of seasonality.

After this, we can use the ACF and PACF plots to determine the order of our ARMA model. To check if our model is good, we should look at 
the residuals and see that they have no pattern and are normally distributed. If they are not, we will refit the model as needed.

```{r}
# Plot quarterly & monthly GDP 
X2raw = get_cansim_vector( c( 
  "monthly GDP (basic prices)" = "v65201210" ,
  "quarterly GDP (market prices)" = "v62305752" ) ,
    start_time = "1900-01-01" ) %>% 
  normalize_cansim_values() 
# (note correct vector code "v62305752" for quarterly GDP)
X2raw %>% filter( Date >= "2010-01-01") %>% 
  ggplot( aes( x = Date, y = VALUE, col = label ) ) +
  geom_line() + geom_point() + ylab("Chained (2012) dollars")
```


```{r}
# (note (basic prices) = (market prices) - (tax & subsidies), 
#  and that is why monthly data values are lower)

# Quartely data 
Q = X2raw %>%  
  filter( VECTOR == "v62305752" ) %>% 
  # find year & quarter
  mutate( Y = year( Date ), Q = quarter( Date ),
          index = yearqtr( Y + Q/4 ) ) %>%  
  xts( x=.$VALUE, order.by =.$index) 
# plot(Q)
# Monthly data 
M = X2raw %>%  
  filter( VECTOR == "v65201210" ) %>% 
  # find year, quarter, month, and month-in-quarter
  mutate( Y = year( Date ), Q = quarter( Date ), 
          index = yearqtr( Y + Q/4 ), 
          M = month( Date ),
          MinQ = paste( "M", M%%3, sep="" ) ) %>%  
  # spread monthly data into 3 columns one for each month-in-quarter
  pivot_wider(id_cols = index, names_from = MinQ, 
              values_from = VALUE ) %>% 
  # take lag for M0
  mutate( M0 = lag(M0) ) %>% 
  xts( x=.[,c("M0","M1","M2")], order.by =.$index) 
#plot(M$M0); plot(M)
# combine & align quarterly series with expanded monthly data
X2 = merge(Q, M, join = "inner" )
plot(X2)


```

Decomposing the Quarterly Data:
```{r}
decompose.xts <-
function (x, type = c("additive", "multiplicative"), filter = NULL) 
{
  dts <- decompose(as.ts(x), type, filter)
  dts$x <- .xts(dts$x, .index(x))
  dts$seasonal <- .xts(dts$seasonal, .index(x))
  dts$trend <- .xts(dts$trend, .index(x))
  dts$random <- .xts(dts$random, .index(x))

  with(dts,
  structure(list(x = x, seasonal = seasonal, trend = trend,
    random = if (type == "additive") x - seasonal - trend else x/seasonal/trend, 
    figure = figure, type = type), class = "decomposed.xts"))
}

plot.decomposed.xts <-
function(x, ...)
{
  xx <- x$x
  if (is.null(xx))
    xx <- with(x,
      if (type == "additive") random + trend + seasonal
      else random * trend * seasonal)
  p <- cbind(observed = xx, trend = x$trend, seasonal = x$seasonal, random = x$random)
  plot(p, main = paste("Decomposition of", x$type, "time series"), multi.panel = 4,
       yaxis.same = FALSE, major.ticks = "days", grid.ticks.on = "days", ...)
}

QDecom = decompose.xts(X2$Q)
plot(QDecom)
```
There's a clear upward trend and seasonality present.

Checking Stationarity of the Quarterly series:
```{r}
adf.test(as.ts(X2$Q)) #Alternative stationary not working
```
Not Stationary, have to implement differencing

Now to try some log differencing:
```{r}
X2.l.d <- diff(log(X2))
plot(X2.l.d)
```


```{r}
# ACF PACF of differenced GDP seems
acf( X2$Q, na.action = na.pass ) 
acf( diff(X2$Q), na.action = na.pass ) ;pacf( diff(X2$Q), na.action = na.pass )
```

```{r}
Qdiff = diff(log(X2$Q), differences = 1)
plot(Qdiff)
adf.test(as.ts(Qdiff)) #Test not working

acf(Qdiff, na.action = na.pass, main='ACF for Differenced Series')
pacf(Qdiff, na.action = na.pass, main='PACF for Differenced Series') 
```
Data is stationary now, we test with AR 1 or 2 and MA 1 for arima model

Standard ARMA model


Arima models w/past information only -> 
      w/ past information with M0 (start of quarter forecast) + M1 (1st month nowcast) + M2 (2nd month nowcast)
```{r}
(auto.model <- auto.arima(Qdiff, seasonal = FALSE))
tsdisplay(residuals(auto.model), lag.max=45, main='(1,1,1) Model Residuals') 
model.1 <- arima( x = Qdiff, order=c(1,1,1))
tsdisplay(residuals(model.1), lag.max=45, main='(1,1,1) Model Residuals')
model.2 <- arima( x = Qdiff, order=c(1,1,1),  xreg = diff(log(X2$M0), differences = 1))
tsdisplay(residuals(model.2), lag.max=45, main='(1,1,1) Model Residuals')
model.3 <- arima( x = Qdiff, order=c(1,1,1),  xreg = diff(log(X2[,c("M0","M1")]), differences = 1))
tsdisplay(residuals(model.3), lag.max=45, main='(1,1,1) Model Residuals')
model.4 <- Arima( y = Qdiff, order=c(1,1,1),  xreg = diff(log(X2[,c("M0","M1","M2")]), differences = 1))
tsdisplay(residuals(model.4), lag.max=45, main='(1,1,1) Model Residuals')
model.1 ; model.2 ; model.3 ; model.4
```

Comparing AIC/BIC of models 
```{r}
AICS <- c(AIC(model.1),AIC(model.2),AIC(model.3),AIC(model.4))
BICS <- c(BIC(model.1),BIC(model.2),BIC(model.3),BIC(model.4))
Compare <- cbind(AICS,BICS)
Compare
```


```{r}
arlm = lm(Q~M0+M1+M2,data = X2)
summary(arlm)
plot(arlm)

arlm2 = lm(Q~M1+M2,data = X2)
summary(arlm2)
plot(arlm2)
```
The previous month's data isn't significant so we generate a new model with the previous second and third month's data:

```{r}
model.5 <- Arima( y = Qdiff, order=c(1,1,1),  xreg = diff(log(X2[,c("M1","M2")]), differences = 1))
tsdisplay(residuals(model.5), lag.max=45, main='(1,1,1) Model Residuals')

AIC(model.5)
```
The AIC for this model is lower than model.4 containing the previous month, we will go forward improving this model for predictions


Analyzing External Data

```{r}
LFS_2018 <- read_csv("LFS_Toronto 2018.csv")
wages <- read_csv("Wages, salaries and employers' social contributions (x 1,000).csv")
```

```{r}
# To get just the data that is seasonally adjusted
wages <- wages %>% filter(`Seasonal adjustment` == "Seasonally adjusted") %>% filter(GEO != "Outside Canada")

wages <- wages %>% mutate(REF_DATE = paste(REF_DATE, "01", sep = "-")) %>% 
  mutate(REF_DATE = ymd(REF_DATE))

wages
```



Analyzing External Data
```{r}
#Attempt at making LFS_2018 a TS
LFS_2018 %>% select(lfsstat) -> lfs_st
lfs_st
ts(lfs_st, start = c(2018, 01), frequency = 12) -> lfs_st_ts

plot(lfs_st_ts)
```


```{r}
#Attempting to make Wages and salaries a TS
wages %>% filter(GEO == "Canada") %>% 
  filter(Sector == "Wages and salaries") %>% 
  select(VALUE) -> CanWS
CanWS


ts(CanWS, start = c(1997,01), end = c(2019,6), frequency = 12) -> CanWS_ts_Monthly

#Make monthly to Quarterly
CanWS_ts_quarterly <- aggregate(CanWS_ts_Monthly, nfrequency = 4)
CanWS_ts_quarterly

#plot the ts 
plot(CanWS_ts_Monthly)
plot(CanWS_ts_quarterly)
plot(decompose(CanWS_ts_Monthly))
plot(decompose(CanWS_ts_quarterly))

#difference to make stationary 
CanWS_ts_log_diff_q <- diff(log(CanWS_ts_quarterly))
CanWS_ts_log_diff_M <- diff(log(CanWS_ts_Monthly))

plot(CanWS_ts_log_diff_q)
plot(CanWS_ts_log_diff_M)
```
```{r}
#Compensation of employees	Time series
#Attempting to make Wages and salaries a TS
wages %>% filter(GEO == "Canada") %>% 
  filter(Sector == "Compensation of employees") %>% 
  select(VALUE) -> Compensation
Compensation


ts(Compensation, start = c(1997,01), end = c(2019,6), frequency = 12) -> Compensation_M

#Make monthly to Quarterly
Compensation_Q <- aggregate(Compensation_M, nfrequency = 4)
Compensation_Q

#plot the ts 
plot(Compensation_M)
plot(Compensation_Q)
plot(decompose(Compensation_M))
plot(decompose(Compensation_Q))

#difference to make stationary 
Comp_l_q <- diff(log(Compensation_Q))
Comp_l_M <- diff(log(Compensation_M))

plot(Comp_l_q)
plot(Comp_l_M)
```

```{r}
#All services-producing industries Time series
wages %>% filter(GEO == "Canada") %>% 
  filter(Sector == "All services-producing industries") %>% 
  select(VALUE) -> services_prod
services_prod


ts(services_prod, start = c(1997,01), end = c(2019,6), frequency = 12) -> services_prod_M

#Make monthly to Quarterly
services_prod_Q <- aggregate(services_prod_M, nfrequency = 4)
services_prod_Q

#plot the ts 
plot(services_prod_Q)
plot(services_prod_M)
plot(decompose(services_prod_M))
plot(decompose(services_prod_Q))

#difference to make stationary 
services_l_q <- diff(log(services_prod_M))
services_l_M <- diff(log(services_prod_Q))

plot(services_l_q)
plot(services_l_M)
```



```{r}
#Trying to fit a model on X2$Q with wages as external data
model.wages <- arima( x = X2$Q, order=c(1,1,0),  xreg = CanWS_ts_quarterly)
model.wages
```
```{r}
QdiffTest2 = cbind(predict(X2$M0)$fitted,predict(X2$M1)$fitted,predict(X2$M2)$fitted)
valid = predict(model.4, newxreg=QdiffTest2)
valid$pred
```
