---
title: "NowCasting GDP"
author: "Minhaz Khan, Navin Chandradat, Bobak Ahmar, Vincent La"
date: "14/09/2019"
output: html_document
---
The problem that we will be tackling is the prediction of the quarters of the fiscal year. To do this, we will employ a technique called 
NowCasting, which is the prediction of the current, and near future by examining data that occur at different frequencies and with 
different lags. To begin, we'll first plot the monthly and quarterly GDPs against eachother. Next, we will fit a model based on the data 
provided and examine the correlation between different months and quarters.

```{r, fig.height=3, fig.width=5}
# load required packages
library(cansim)
library(tidyverse)
library(lubridate)
library(modelr)
library(broom)
library(astsa)
library(forecast)
library(xts) # better ts objects, including quarterly series

#### Problem 2 ####

# plot quarterly & monthly GDP 
#This code is from the Draft
get_cansim_vector( c( 
  "monthly GDP" = "v65201210",
  "quarterly GDP" = "v1000000673") ,
    start_time = "2015-01-01" ) %>% 
  normalize_cansim_values() %>% 
  ggplot( aes( x = Date, y = VALUE, col = label ) ) +
  geom_line() + geom_point() + ylab("Chained (2012) dollars") +
  ggtitle("Problem 2: Plot of quarterly & monthly GDP")


```
The graph shows that both the monthly and quarterly GDPs increase at almost exactly the same rate. This suggests that
perhaps the two are highly correlated.


In order to get a closer look at the existing pattern, we separated the monthly and quarterly GDP and then graphed them.
```{r}
get_cansim_vector( c( 
  "monthly GDP (basic prices)" = "v65201210",
  "quarterly GDP (expend-based)" = "v62305723") ,
    start_time = "2010-01-01" ) %>% 
  normalize_cansim_values() %>% 
  ggplot( aes( x = Date, y = VALUE, col = label ) ) +
  geom_line() + geom_point() + ylab("Chained (2012) dollars")
```

Retrieving the data frame:
```{r}
get_cansim_vector( c( 
  "monthly GDP (basic prices)" = "v65201210",
  "quarterly GDP (expend-based)" = "v62305723") ,
    start_time = "2009-01-01" ) %>% 
    normalize_cansim_values() -> ncastDF
```

Summary Statistics for monthly and quarterly data
```{r}
ncastDF %>% group_by(label) %>% summarise(time_mean = mean(VALUE), time_var = var(VALUE), time_med = median(VALUE))
```

Spreading the labels to their own columns for model testing
```{r}
ncastDF %>% spread(label,VALUE) -> ncastSP
ncastSP
```

Checking out the yearly pattern for some quarters and months
```{r}
glimpse(ncastDF)
ncastDF %>% filter(label == "quarterly GDP (expend-based)" & year(Date) ==2010) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()

ncastDF %>% filter(label == "monthly GDP (basic prices)" & year(Date) ==2010) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()
ncastDF %>% filter(label == "monthly GDP (basic prices)" & year(Date) ==2011) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()
ncastDF %>% filter(label == "monthly GDP (basic prices)" & year(Date) ==2012) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()
ncastDF %>% filter(label == "monthly GDP (basic prices)" & year(Date) ==2013) %>% ggplot(aes(Date,VALUE,col=label))+geom_line()
```


```{r}
ggplot(ncast.1,aes(x=Date,y= VALUE,group = Date))+geom_boxplot()

```

Here, we can see that the variance between the values are more or less the same time progresses, while the mean steadily increases in an almost linear fashion.


Taking a sample year to work with:
```{r}
ncastSP %>% filter(year(Date) >= 2018 & year(Date) <= 2019) -> ncast1


ncast1 %>% mutate(monthly = case_when(
                                  `monthly GDP (basic prices)` == NA ~ 0, 
                                  is.na(`monthly GDP (basic prices)`) ~ 0,
                                  TRUE ~ `monthly GDP (basic prices)`)) %>%
  mutate(quarterly = case_when(
                                  `quarterly GDP (expend-based)` == NA ~ 0, 
                                  is.na(`quarterly GDP (expend-based)`) ~ 0,
                                  TRUE ~ `quarterly GDP (expend-based)`)) %>% 
  select(REF_DATE,releaseTime,Date,monthly,quarterly) -> ncastMQ



```
Replaced the NA with zeroes to work with models and other analysis.


Sample model exploring the relationship between the quarterly and monthly values
```{r}
cor(ncastMQ$quarterly,ncastMQ$monthly)
ncast.lm = lm(quarterly~monthly+Date,data = ncastMQ)
summary(ncast.lm)
```
The model is off due to majority of the zeroes in our data


```{r}
ncastMQ %>% spread(Date,monthly) 
```
Ideal data frame to test the prediction of each quarter within a 3 month cohort.

*Plan of Attack*
Since the data we have is clearly dependent, i.e. the GDP for previous months would be dependent on eachother, we could use time series 
methodologies to estimate the present and near future, in particular, we will attempt to fit an ARMA model for the data.

In order to do this, we must construct a model of our time series. The essence of how we want to construct our model is that we want to 
create a three month cohort for each quarter and attach them together. So what this means is that we want to create these quarterly bins 
for each month starting with one year and experimenting with that. For example, if we were to predict the GDP for the first quarter of 
2019, we would use the monthly GDP data from the previous 3 months. 

Furthermore, in order to make full use of these methodologies, we’ll also check that our model is stationary. We may obtain evidence of 
this by looking back even further, and see if there are any discrepancies between the joint distribution of monthly GDPs, by using ACF 
and PACF plots. Additionally, we may check if the mean and variance functions are constant, or if γ(s,t) is function of h = s-t. If at 
least one of these are not fulfilled we may have to change our model such that it will. There also may be the problem of seasonality in 
the mean, for example the GDP of a country that relies heavily on tourist will fluctuate up and down throughout the year. In this case, 
we could employ the moving average smoother to get rid of seasonality.

After this, we can use the ACF and PACF plots to determine the order of our ARMA model. To check if our model is good, we should look at 
the residuals and see that they have no pattern and are normally distributed. If they are not, we will refit the model as needed.

```{r}
# Plot quarterly & monthly GDP 
X2raw = get_cansim_vector( c( 
  "monthly GDP (basic prices)" = "v65201210" ,
  "quarterly GDP (market prices)" = "v62305752" ) ,
    start_time = "1900-01-01" ) %>% 
  normalize_cansim_values() 
# (note correct vector code "v62305752" for quarterly GDP)
X2raw %>% filter( Date >= "2010-01-01") %>% 
  ggplot( aes( x = Date, y = VALUE, col = label ) ) +
  geom_line() + geom_point() + ylab("Chained (2012) dollars")
```


```{r}
# (note (basic prices) = (market prices) - (tax & subsidies), 
#  and that is why monthly data values are lower)

# Quartely data 
Q = X2raw %>%  
  filter( VECTOR == "v62305752" ) %>% 
  # find year & quarter
  mutate( Y = year( Date ), Q = quarter( Date ),
          index = yearqtr( Y + Q/4 ) ) %>%  
  xts( x=.$VALUE, order.by =.$index) 
# plot(Q)
# Monthly data 
M = X2raw %>%  
  filter( VECTOR == "v65201210" ) %>% 
  # find year, quarter, month, and month-in-quarter
  mutate( Y = year( Date ), Q = quarter( Date ), 
          index = yearqtr( Y + Q/4 ), 
          M = month( Date ),
          MinQ = paste( "M", M%%3, sep="" ) ) %>%  
  # spread monthly data into 3 columns one for each month-in-quarter
  pivot_wider(id_cols = index, names_from = MinQ, 
              values_from = VALUE ) %>% 
  # take lag for M0
  mutate( M0 = lag(M0) ) %>% 
  xts( x=.[,c("M0","M1","M2")], order.by =.$index) 
#plot(M$M0); plot(M)
# combine & align quarterly series with expanded monthly data
X2 = merge(Q, M, join = "inner" )
plot(X2)
```

Now to try some log differencing:
```{r}
X2.l.d <- diff(log(X2))
plot(X2.l.d)
```


```{r}
# ACF PACF of differenced GDP seems
acf( diff(X2$Q), na.action = na.pass ) 
acf( X2.l.d$Q, na.action = na.pass ) ;pacf( diff(X2$Q), na.action = na.pass )
```

Arima models w/past information only -> 
      w/ past information with M0 (start of quarter forecast) + M1 (1st month nowcast) + M2 (2nd month nowcast)
```{r}
model.1 <- arima( x = X2.l.d$Q, order=c(1,1,0) )
model.2 <- arima( x = X2.l.d$Q, order=c(1,1,0),  xreg = X2.l.d$M0)
model.3 <- arima( x = X2.l.d$Q, order=c(1,1,0),  xreg = X2.l.d[,c("M0","M1")])
model.4 <- arima( x = X2.l.d$Q, order=c(1,1,0),  xreg = X2.l.d[,c("M0","M1","M2")])
model.1 ; model.2 ; model.3 ; model.4
```

Comparing AIC/BIC of models 
```{r}
AICS <- c(AIC(model.1),AIC(model.2),AIC(model.3),AIC(model.4))
BICS <- c(BIC(model.1),BIC(model.2),BIC(model.3),BIC(model.4))
Compare <- cbind(AICS,BICS)
Compare
auto.arima(X2.l.d$Q)
```


```{r}
# model w/ past information only 
model.1 <- arima( x = X2$Q, order=c(1,1,0) )
model.1
```

```{r}
# model w/ past information + M0 (start of quarter forecast)
model.2 <- arima( x = X2$Q, order=c(1,1,0),  xreg = X2$M0)
model.2
```

```{r}
# model w/ past information + M0 + M1 (1st month nowcast)
model.3 <- arima( x = X2$Q, order=c(1,1,0),  xreg = X2[,c("M0","M1")])
model.3
```

```{r}
# model w/ past information + M0 + M1 + M2 (2nd month nowcast)
model.4 <- arima( x = X2$Q, order=c(1,1,0),  xreg = X2[,c("M0","M1","M2")])
model.4
```

```{r}
arlm = lm(Q~M0+M1+M2,data = X2)
summary(arlm)
predict(arlm, n.ahead=12)
```

```{r}
library(aTSA)
test_model = arima( x = X2$Q, order=c(1,1,0),  xreg = X2[,c("M0","M1","M2")])
plot(test_model$residuals)
adf.test(X2.l.d$Q, nlag=NULL, output = TRUE)
adf.test(X2.l.d$M0, nlag=NULL, output = TRUE)
adf.test(X2.l.d$M1, nlag=NULL, output = TRUE)
adf.test(X2.l.d$M2, nlag=NULL, output = TRUE)
```
Note: For some reason cannot reject ADF null

Now to try and compare some models:
```{r}
auto.arima(X2$Q)
```

For the models we tried:
```{r}
AIC(model.1)
BIC(model.1)
```

```{r}
AIC(model.2)
BIC(model.2)
```

```{r}
AIC(model.3)
BIC(model.3)
```

```{r}
AIC(model.4)
BIC(model.4)
```

```{r}
AIC(arlm)
BIC(arlm)
```


